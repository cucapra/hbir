target{
    memory g[4]{
        size 8G;
        width 8B;
    };

    tile t[4][4];

    // list available acceleration structures
    matmul m[1][1] {
        // <required> this tells the compiler how it should load stuff
        // # are fixed parameters of the accel
        // then io
        signature #(int t = 4, int m = 4, int n = 4)
            (input int[m][t] A, input int[t][n] B, output int[m][n] C) {

            // <optional> specify how stuff should be loaded? i.e. prefetching for it
            // if the accel employs a reuse pattern want to reflect that here
            // i.e. if B is resued then don't need to fetch as often
            prefetch A[m][t] every 4 cycles;
            prefetch B[t][n] every 10 cycles;
            receive C[m][n] every 4 cycles;

            // if not a fixed speed, maybe can use val/rdy event triggers?

        }

        // <optional> define the computation in terms of cpu ops in case we need to fallback to it
        // this has the same semantics as the code section EXCEPT can't call cells in the target section
        compute {
            for(int j = 0; j < m; j=j+1){
                for(int i = 0; i < n; i=i+1){
                    for(int k = 0; k < t; k=k+1){
                        C[j][i] += A[j][k] * B[k][i];
                    }
                }
            }
        }

        // <optional> this accel potentially has some internal memory
        memory matpad {
            size 4K;
            width 16B;
        }
    };
}

// in the compute group, we let the compiler know it can use the matmul we defined in the target section
config{
    group tg[4][3] {
        tile target.t[x][y];

        // the group has a matmul unit in it as well
        matmul target.m;
    };
}

// global data structure whose dimension is not related to matmul parameters
data{
    m = 16;
    n = 16;
    t = 16;

    A: int[m][t] -> chunked[target.g.x_max][target.g.x_max] {
        //target.g[x]; // redundant?
    };

    B: int[t][n] -> chunked[target.g.x_max][target.g.x_max] {
        //target.g[x];
    };

    C: int[m][n] <- chunked[target.g.x_max][target.g.x_max] {
        //target.g[x];
    };
}

// what computation we want to run
code{
    config.tg[x][y]{

        // call standard cell/primitive

        // infer how many times we need to run this based on the sizes of A,B
        // and the signature of 'matmul'
        for (i in alex_iterator<data,target>) {
            // <list of outputs> = <accel> <list of inputs>
            C[i] = m.matmul[1][1] A[i] B[i];
        }
    
        bsg_finish();
    }
}

