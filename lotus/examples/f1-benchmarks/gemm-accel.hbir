// This example illustrates the near-term goals for the HammerBlade IR (HBIR).
// Many syntax and features present here likely don't work in the current implementation.


// ----------------------------------------------------------------------------
// Code Section: The algorithm we want to run. Compilation is informed by the other 3 sections
// ----------------------------------------------------------------------------
code{
    config.tg[x][y]{

        // infer how many times we need to run the loops based on the sizes of layouts

        for(int j in iterator<m, ml, x, y>){

            for(int i in iterator<n, ml, x, y>){

                for(int k in iterator<t, ml, x, y>){
                    
                    // *** we 'call' the hardware structure we want to use like a function
                    C[j][i] += m.matmul[1][1] ( A[j][k] , B[k][i] );

                    // maybe write accum code here
                }
            }
        }
    
        bsg_finish();

    }
}

// ----------------------------------------------------------------------------
// Target Section: Specify what hardware resources are present in the chip (at design time or compile time)
// ----------------------------------------------------------------------------
target{
    // declare global memory
    memory g[4]{
        size 8G;
        width 8B;
    };

    // declare available tiles
    tile t[4][4] {
        memory l{
            size 4K;
            width 32B;
        }
    };

    // ----------------------------------------------------------------------------
    // list available acceleration structures
    // ----------------------------------------------------------------------------

    // Cornell dense matrix multiply accelerator
    matmul m[1][1] {
        // <required> this tells the compiler how it should load stuff to accel
        signature #(int t = 4, int m = 4, int n = 4)
            (input int[m][t] A, input int[t][n] B, output int[m][n] C) {

            // compiler will try to insert communication instructions to accel with best effort (??)
            prefetch A[m][t] every 4 cycles;
            prefetch B[t][n] every 10 cycles;
            receive C[m][n] every 4 cycles;

        }

        // <optional> define the computation in terms of cpu ops in case we need to fallback to it
        compute {
            for(int j = 0; j < m; j=j+1){
                for(int i = 0; i < n; i=i+1){
                    for(int k = 0; k < t; k=k+1){
                        C[j][i] += A[j][k] * B[k][i];
                    }
                }
            }
        }

        // <optional> this accel potentially has some internal memory
        memory matpad {
            size 4K;
            width 16B;
        }
    };

    // potentially others that can be configured at runtime
}

// ----------------------------------------------------------------------------
// Configuration Section: Devote hardware resources to a computation
// ----------------------------------------------------------------------------
config{
    group tg[4][3] {
        tile target.t[x][y];

        // the group has a matmul unit in it as well
        matmul target.m;
    };
}

// ----------------------------------------------------------------------------
// Data Section: Specify memory layout of buffers across available memories.
// ----------------------------------------------------------------------------
// somewhat similar to the "schedule" in halide. the location of the data might dictate how compute is scheduled (blocked)
data{
    // declare important dimensions
    m = 16;
    n = 16;
    t = 16;

    // declare matrix layout in memory
    layout ml {
        chunked[target.g[x]][target.g[x]];
    }

    // declare matrices
    A: int[m][t] -> ml;

    B: int[t][n] -> ml;

    C: int[m][n] <- ml;

    // also put chunks of this into spad memory?
}



// ----------------------------------------------------------------------------
// Anticipated compilation behavior
// ----------------------------------------------------------------------------

// we envision our future compiler to synthesize the following by inference informed by other 3 sections
// here's what the code might look like
synth_single_core {
    // blk size inferred from hardware signature
    int blk = 4;

    // block the orignal three loops
    for(int j = 0; j < m; j += blk){       

        for(int i = 0; i < n; i += blk){

            for(int k = 0; k < t; k += blk){

                // ----------------------------------------------------------------------------
                // accumulate within a block i.e. use the accel structure
                // ----------------------------------------------------------------------------
                A_blk = accel_load A[blk][blk];

                nop;
                B_blk = accel_load B[blk][blk];

                nop;
                nop; // in more complex codes can try to put non-dependent instructions here
                nop;
                nop;
                psum[blk][blk] = accel_store C_blk[blk][blk];

                // stretch goal!
                // accumlate into C buffer on a CPU
                for (int jb = 0; jb < blk; jb++) {
                    for (int ib = 0; ib < blk; ib++) {
                        C[j+jb][i+ib] += psum[j][i];
                    }
                }

            }
        }
    }
}


// how to transform code based on the data layout and the target 
synth_multi_core {
    
    for(int i in iterator<m, ml, x, y, tg>)

    // -->

    // in the case of chunked memory
    int mem_idx = x + y * tg.x_len * chunk_len(m, ml);
    for(int i = mem_idx; i < mem_idx + chunk_len; i++);

    // in the case of strided memory
    int i0 = x + y * tg.x_len;
    int stride = tg.x_len * tg.y_len;
    for(int i = i0; i < m; i++stride);


    //
    // in combination with target section  (??)
    //

    int mem_idx = x + y * tg.x_len * chunk_len(m, ml);
    for(int j = mem_idx; j < mem_idx + chunk_len; j += blk);  

    int i0 = x + y * tg.x_len;
    int stride = tg.x_len * tg.y_len * blk;
    for(int i = i0; i < m; i++stride);



}