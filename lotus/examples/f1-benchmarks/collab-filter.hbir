//This code maps to brg_vvadd in the bsg_manycore repository


// TODO: target section should have list of avail accel , what ops they can do and how many
// this will kind of be like a "standard cell" in compute primitive terms
target{
    memory g[4]{
        size 8G;
        width 8B;
    };

    tile t[4][4];
}

// TODO: the config section should talk about how we group cores or accels together for collaborative work
config{
    group tg[4][3] {
        tile target.t[x][y];
    };
}

// can we declare non-regular structures like trees? lotus crunches them down to arrays
// or structure types other than primitive? i.e. latent vec
    // can we support this? otherwise will be 2d array
    //typedef latent_vec {
    //    int vec[2];
    //};
data{
    users = 2;
    items = 2;
    edges = users * items;

    latent_user: int[users] = block[target.g.x_max] {
        target.g[x];
        global;
        chunked;
        host;
    };

    latent_item: int[items] = block[target.g.x_max] {
        target.g[x];
        global;
        chunked;
        host;
    };

    // answers that we hide from the model
    hidden_preferences : int[edges] = block[target.g.x_max] {
        target.g[x];
        global;
        chunked;
        host;
    };


}

// TODO: code should call some primitives specified in teh target section to use the accel
// maybe in this one we have a vvadd accel

// let's do only do a single user to multiple item
// also let's us avoid having two kernels

// TODO first loop should be dot product of arrays
code{
    config.tg[x][y]{
        
        float lr = 0.1;
        for (int u = 0; u < users; u=u+1) {
            for (int i = 0; i < items; i=i+1) {
                // make prediction via DOT product
                int prediction = 0;
                for (int l = 0; l < 1; l=l+1) {
                    prediction += latent_user[u] * latent_item[i];
                }

                int edgeIdx = i + u * items;
                int error = prediction - hidden_preferences[edgeIdx];
                
                // update latent prediction vectors
                for (int l = 0; l < 1; l=l+1){
                    latent_user[u] += lr * (error * latent_item[i] - lambda * latent_user[u]);
                    latent_item[i] += lr * (error * latent_user[u] - lambda * latent_item[i]);
                }
            }
        }

        bsg_finish();

    }
}


// in reality would do the previous two loops for many “training” iterations
